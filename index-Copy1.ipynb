{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7ea5b4",
   "metadata": {},
   "source": [
    "## Building a Machine Learning Classification Model to Predict Customer Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ca56d",
   "metadata": {},
   "source": [
    "* Student: Wambui Munene\n",
    "* Student pace: DSPT08\n",
    "* Scheduled project review date/time: 23/12/2024\n",
    "* Instructor name: Samuel Karu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95cbdb5",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The telkom industry is highly competitive with multiple players within any given jurisdiction. Acquiring new customers involves huge marketing costs, that include huge advertising budgets and commissions to sales agents. It therefore becomes imperative to retain the those customers once they are acquired. Churn which is refers to the number of customers who cease doing business with a company within a given period, is a closely watched metric in the telco industry. It is the motivation of every telco company to understand the features or characteristics of a customer who is likely to 'churn'. With this understanding, the company can get ahead of the problem, and develop initiatives that target these specific customers , to discourage them from ceasing doing business with the company.\n",
    "\n",
    "In this project, I will use a dataset from https://www.kaggle.com/ based on data that details various call patterns and spend of customers as well as their locations https://www.kaggle.com/datasets/becksddf/churn-in-telecoms-dataset .\n",
    "\n",
    "Using this data set I will:\n",
    "+ Examine the features and using domain knowledge select the features to use in my predictive model\n",
    "+ Using these features build a classifier to predict whether a customer will stop doing business with SyriaTel\n",
    "+ Based on the model metrics, determine if these features have any predictive patterns\n",
    "+ If the features indeed have predictive patterns, use the most optimal version of the model to test customer data and identify those customers that are most likely to churn\n",
    "+ The company will then use this predicted data to make proactice startegies to retain these 'at risk' customers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302b6c6",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "SyriaTel is intentional about reducing the cost of customer churn. They have hired me to develop a classification model that is able to a higher degree, predict if a customer is likely to churn i.e. terminate their contract. They have provided me with a historical dataset of customer call and spend characteristics and whether or not they left the network after a period of time. With the model model their Marketing and Revenue Assurance departments will be able to test future customer data to predict the likelihood of a customer leaving the network. With these predictions, they will be able to develop retention startegies specifically targeted to these customers to discourage them from leaving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b79cca",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    " ### Business Objectives\n",
    " + **Goal:**\n",
    "     + Train a classification model using the provided historical data to determine if and what features are useful in predicting churn.\n",
    " + **Specific Objectives:**\n",
    "     + Determine if the data provided has any predictive power on the target using Logistic regression or decision trees.\n",
    "     + Through model optimization, identify the features that have the best predictive power \n",
    "     + Use the model on future customer data to predict \"at risk\" customers\n",
    "     + Provide insights on factors affecting customer churn and suggest approriate remedies\n",
    "     \n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26245a25",
   "metadata": {},
   "source": [
    "### 1. 0 Industry Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad685f",
   "metadata": {},
   "source": [
    "The kaggle data set consist of fairly straightforward and well formated data. It has critical data usage as well as customer behavior columns. Based on **industry standards** the following features from the data set are commonly associated with customer churn and will be considered as model features that have an impact on the traget variable 'churn'.\n",
    "\n",
    "**Usage Patterns:** 'total day minutes', 'total day calls','total eve calls', 'total eve minutes','total night calls','total night minutes','total intl calls', and 'total intl minutes' are critical columns for determining churn. High usage of calls and minutes can indicate customer engagement and satisfaction, while low usage might suggest dissatisfaction.\n",
    "\n",
    "**Charges:** 'total day charge','total eve charge','total night charge', and 'total intl charge' are also important columns. Higher charges can lead to customer distasfaction if they feel they are not getting value for money.\n",
    "\n",
    "**Service Quality:** Features like 'International plan' and 'voice mail plan' can reflect a very high expectation from customers who are enrolled in those plans, and can have a direct impact on satisfaction levels and therefore, churn.\n",
    "\n",
    "**Customer Support:** 'customer service calls' a high number of customer service calls can indicate issues of service quality or customer dissatisfaction.\n",
    "\n",
    "**Account Length:** The 'account length' feature is equally important as longer account lengths generally indicate customer loyalty, while shorter account lengths may suggest a higher likelihood of churn.\n",
    "\n",
    "The following features from the data set are deemed to have little or no predicted power and will be excluded from the model:\n",
    "\n",
    "+ 'state'\n",
    "+ 'area code'\n",
    "+ 'phone number'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2becbf8f",
   "metadata": {},
   "source": [
    "### 2.0 Understanding the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6c11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries for data analysis and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da46691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account length  area code phone number international plan  \\\n",
       "0    KS             128        415     382-4657                 no   \n",
       "1    OH             107        415     371-7191                 no   \n",
       "2    NJ             137        415     358-1921                 no   \n",
       "3    OH              84        408     375-9999                yes   \n",
       "4    OK              75        415     330-6626                yes   \n",
       "\n",
       "  voice mail plan  number vmail messages  total day minutes  total day calls  \\\n",
       "0             yes                     25              265.1              110   \n",
       "1             yes                     26              161.6              123   \n",
       "2              no                      0              243.4              114   \n",
       "3              no                      0              299.4               71   \n",
       "4              no                      0              166.7              113   \n",
       "\n",
       "   total day charge  ...  total eve calls  total eve charge  \\\n",
       "0             45.07  ...               99             16.78   \n",
       "1             27.47  ...              103             16.62   \n",
       "2             41.38  ...              110             10.30   \n",
       "3             50.90  ...               88              5.26   \n",
       "4             28.34  ...              122             12.61   \n",
       "\n",
       "   total night minutes  total night calls  total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   total intl minutes  total intl calls  total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   customer service calls  churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data as a DataFrame and display the first 5 columns\n",
    "df = pd.read_csv('telco_churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05819b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data set consists of 3333 rows\n",
      "This data set consists of 21 columns\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the data\n",
    "df.shape\n",
    "print(f\"This data set consists of {df.shape[0]} rows\")\n",
    "print(f\"This data set consists of {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2677e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'account length', 'area code', 'phone number',\n",
       "       'international plan', 'voice mail plan', 'number vmail messages',\n",
       "       'total day minutes', 'total day calls', 'total day charge',\n",
       "       'total eve minutes', 'total eve calls', 'total eve charge',\n",
       "       'total night minutes', 'total night calls', 'total night charge',\n",
       "       'total intl minutes', 'total intl calls', 'total intl charge',\n",
       "       'customer service calls', 'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a264bbc",
   "metadata": {},
   "source": [
    "##### add column decriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a28e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   3333 non-null   object \n",
      " 1   account length          3333 non-null   int64  \n",
      " 2   area code               3333 non-null   int64  \n",
      " 3   phone number            3333 non-null   object \n",
      " 4   international plan      3333 non-null   object \n",
      " 5   voice mail plan         3333 non-null   object \n",
      " 6   number vmail messages   3333 non-null   int64  \n",
      " 7   total day minutes       3333 non-null   float64\n",
      " 8   total day calls         3333 non-null   int64  \n",
      " 9   total day charge        3333 non-null   float64\n",
      " 10  total eve minutes       3333 non-null   float64\n",
      " 11  total eve calls         3333 non-null   int64  \n",
      " 12  total eve charge        3333 non-null   float64\n",
      " 13  total night minutes     3333 non-null   float64\n",
      " 14  total night calls       3333 non-null   int64  \n",
      " 15  total night charge      3333 non-null   float64\n",
      " 16  total intl minutes      3333 non-null   float64\n",
      " 17  total intl calls        3333 non-null   int64  \n",
      " 18  total intl charge       3333 non-null   float64\n",
      " 19  customer service calls  3333 non-null   int64  \n",
      " 20  churn                   3333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 524.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get column attributes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364762e",
   "metadata": {},
   "source": [
    "The target column is boolean. This will be converted to integer. There are no missing values in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf6326ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirming there are no Null values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b723a05",
   "metadata": {},
   "source": [
    "#### Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistical summary of the numerical columns\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e34d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistical summary of the categorical columns\n",
    "df.describe(include='O').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e930840",
   "metadata": {},
   "source": [
    "The 'international plan' and 'voice mail plan' columns are binary columns(Yes/No). These will be One-Hot-Encoded and converted to integers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a52e3",
   "metadata": {},
   "source": [
    "### 2.1 Data Cleaning and Feature Engineering\n",
    "\n",
    "In this section I will perform the following tasks:\n",
    "+ Drop columns that are not critical to the model\n",
    "+ Convert column names to CamelCase for easier readability and display\n",
    "+ Convert the target column 'churn' from boolean to integer\n",
    "+ One-Hot Encode the 2 categorical columns 'international plan'and 'voice mail plan' \n",
    "+ Check for, and remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a718a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the DataFrame before we clean\n",
    "df1 = df.copy(deep=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8419928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unimportant columns\n",
    "\n",
    "df1 = df1.drop(columns=['phone number','state','area code'],axis=1)\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to capitalize the first letter of each word in column names\n",
    "def capitalize_columns(df):\n",
    "    df1.columns = [' '.join(word.capitalize() for word in col.split()) for col in df1.columns]\n",
    "    return df1\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df1 = capitalize_columns(df1)\n",
    "                   \n",
    "#Apply the function to the DataFrame \n",
    "df1 = capitalize_columns(df1) \n",
    "\n",
    "df1.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f10a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove the white spaces from column names\n",
    "def remove_spaces(df1): \n",
    "    df1.columns = [col.replace(' ', '') for col in df1.columns]\n",
    "    return df1\n",
    "                   \n",
    "#Apply the function to the DataFrame \n",
    "df1 = remove_spaces(df1) \n",
    "\n",
    "# Display the updated DataFrame columns\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c477ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6443e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # OneHotCode the two categorical columns of interest\n",
    "\n",
    "df1 = pd.get_dummies(df1, columns=['InternationalPlan','VoiceMailPlan'],drop_first=True)\n",
    "\n",
    "# Convert the one-hot encoded columns and the target colum 'Churn' from boolean to integer \n",
    "for col in df1.columns: \n",
    "    if df1[col].dtype == 'bool':\n",
    "          df1[col] = df1[col].astype(int) \n",
    "        \n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55171db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the DataFrame\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c7e0d1",
   "metadata": {},
   "source": [
    "All the columns are now numerical. The columns are now 18 from 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df1, columns):\n",
    "    for col in columns:\n",
    "        # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "        Q1 = df1[col].quantile(0.25)\n",
    "        Q3 = df1[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1  # Interquartile Range\n",
    "\n",
    "        # Define lower and upper bounds for detecting outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Filter out outliers\n",
    "        df1 = df1[(df1[col] >= lower_bound) & (df1[col] <= upper_bound)]\n",
    "    \n",
    "    return df1\n",
    "\n",
    "# List of columns to check for outliers (excluding 'Churn')\n",
    "feature_columns = [col for col in df1.columns if col != 'Churn' and df1[col].dtype in [np.int64, np.float64]]\n",
    "\n",
    "# Apply the function to remove outliers\n",
    "df2 = remove_outliers(df1, feature_columns)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the data after removing outliers\n",
    "df2.shape\n",
    "print(f\"This data set consists of {df2.shape[0]} rows\")\n",
    "print(f\"This data set consists of {df2.shape[1]} columns\")\n",
    "\n",
    "# The number of rows have reduced from 3333 to 2797."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a326d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate boxplots for cleaned columns to confirm outliers have been dropped\n",
    "plt.figure(figsize=(15,8))\n",
    "df2.boxplot(feature_columns, boxprops=dict(linewidth=1 ))\n",
    "plt.title('Checking for Outliers')\n",
    "plt.ylabel('Values')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "                          \n",
    "plt.show();\n",
    "\n",
    "# No values outside the IQR showing outliers have been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff7bff",
   "metadata": {},
   "source": [
    "The outliers are now eliminated, and the columns are cleaned; we can go ahead and start EDA. But first we save the clean dataframe to a CSV and make a copy of the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the clean dataframe in csv format\n",
    "df2.to_csv('telco_churn_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a14693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the clean dataframe\n",
    "df2=df2.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462bfc52",
   "metadata": {},
   "source": [
    "### 2.2 Exploratory Data Analysis\n",
    "\n",
    "I will perform various univariate, bivariate and multivariate data analysis to better understand the data, These will include:-\n",
    "\n",
    "+ **Summary Statistics:** To get a quick overview of the central tendency and dispersion of the dataset's distribution.\n",
    "+ **Correlation Matrix:** To understand the relationships between nemerical features\n",
    "+ **Histograms:** To understand numerical features distributions\n",
    "+ **Class Distribution:** Analyze the distribution of the target variable churn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128edcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the clean dataset and create a new dataframe\n",
    "data = pd.read_csv('telco_churn_clean.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be50a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2522868",
   "metadata": {},
   "source": [
    "#### 2.2.1 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62666c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive statistics for the non-binary nemeric columns\n",
    "desc_columns = [col for col in data.columns if col not in ['Churn','InternationalPlan_yes','VoiceMailPlan_yes'] \n",
    "                   and data[col].dtype in [np.int64, np.float64]]\n",
    "data[desc_columns].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e7f29",
   "metadata": {},
   "source": [
    "The summary statistics show some variability in the local  minutes/calls as well as in voicemail messages. The number of Customer service calls made are surprisingly not many, with the maximum number of calls being 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558bb948",
   "metadata": {},
   "source": [
    "#### 2.2.2 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = data.corr().round(2)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac0cac",
   "metadata": {},
   "source": [
    "Not surprisingly, the total (day,evening,night international) minutes have a perfect linear relationship with the total(day,evening,night,international) charges. This is because charges are based on minutes. Being on a voice plan is also very correlated to the number of voice mail minutes. This **multicollinearity** can impact model performance and interpretability. Highly correlated predictors can contribute to overfitting where the model performs well on training data but poorly on unseen data.  Proposed remedy is to drop one of the correlated predictors form the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db04353",
   "metadata": {},
   "source": [
    "#### 2.2.3 Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of continous columns to plot\n",
    "continous_cols = [col for col in data.columns if col not in ['Churn','InternationalPlan_yes','VoiceMailPlan_yes'] \n",
    "                   and data[col].dtype in [np.int64, np.float64]]\n",
    "\n",
    "# Create subplots                               \n",
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "for i,col in enumerate (continous_cols):\n",
    "    plt.subplot(5,3,i+1)\n",
    "    sns.histplot(data[col],bins=20,kde=True,color='blue',alpha=0.7,edgecolor='black',hue='Churn')\n",
    "    plt.title(col)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18888307",
   "metadata": {},
   "source": [
    "The charts show that the number of calls and charges for local calls are approximately normally distributed; International calls distribution is right-skwed with most values concentrated around 4 and a few extending to 10; The total international charge distribution is approximately normal. The Customer Service Calls show distinct peaks at 1,2,3, indicating that these values are more frequent. Number of Voice Mail Messages is highly skewed to the right, with most values concentrated around 0 and a few exceeding 50. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f14ed5",
   "metadata": {},
   "source": [
    "#### 2.2.4 Class distribution of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the value counts of the target variable\n",
    "\n",
    "print(data['Churn'].value_counts())\n",
    "print(data['Churn'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6fb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the classes\n",
    "sns.countplot(x='Churn', data=data)\n",
    "plt.title('Class Distribution of Churn')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd7e64",
   "metadata": {},
   "source": [
    "The output indicates that 89% of the customersdo not churn while 11% do churn. This is significant class imbalance. This can significantly affect impact the reliability of the model in the following ways:-\n",
    "+ **Bias:** A model trained on imbalanced data may become biased biased toward the majority class. The bias may lead to a high accuracy score, but fail to correctly predict the minority class.\n",
    "+ **Poor Performance on Minority Class:** Where detecting the minority class is of critical class, like in our model, the model may have poor performance in detecting the minoity class i.e. incorrectly fail to predict churn.\n",
    "\n",
    "I will address the class problem using **SMOTE** (Synthetic Minority Over-Sampling Technique) an oversampling technique that increases the number of instances in the minority class during the modeling process below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf3431",
   "metadata": {},
   "source": [
    "### 4.0 Modeling\n",
    "\n",
    "In this section I will follow a model iteration plan that addresses class imbalance and leverages feature importance and hyperparameters tuning. The following is a step by step plan to build and improve the model, starting with a base logistic model and incorporating SMOTE for oversampling, Random Forest for feature selection,and GridSearchCV for hyperparameter tuning:-\n",
    "\n",
    "+ **Data Preparation:** In this section, I will prepare the data for modeling. Since I have alredy handled data cleaning and one-hot encoding, I will address multicollinearity. I will use the correlation matrix in section 2.2.2 above and remove highly correlated features.\n",
    "+ **Baseline Logistic Regression Model:** I will split the data into training and test sets, train the logistic regression model on the training data and evaluate the baseline model using appropriate metrics.\n",
    "+ **Handle Class Imbalance:** I will use **SMOTE** to oversample the minority class in the training set. I will re-train the model on the oversampled training data and evaluate the model on the original test set. I will compare the performance metrics before and after SMOTE application.\n",
    "+ **Feature Selection:** I will use **Random Forest** to calculate feature importances and identify and retain the most important features. I will then retrain the model with these features and compare the results with those obtained above.\n",
    "+ **Cross-Validation:** I will use cross-validation to ensure the model's performance is consistent and not dependent on a specific train-test split.\n",
    "+ **Hyperparameter Tuning:** I will use **GridSearchCV** to find the optimal hyperparameters for the logistic regression model, and may include regularization (L1/L2) to handle overfitting. I will re-train the model with optimal hyperparameters and optimal features obtained in feature selection and evaluate and comapre performance metrics with previous iterations.\n",
    "+ **Use other Modeling Algorithms**: I will train a different model algorithm e.g. Decision Trees and compare their performance with the logistic regression \n",
    "+ **Final Model Selection:** I will select the model with the best performance based on validation metrics, Interpret this final model's results, and generate a report on model performance, feature importance and the handling of class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f3586",
   "metadata": {},
   "source": [
    "### 4.1 Data Preparation\n",
    "In this section I will use the correlation heat map to remove highly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55352155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the DataFrame before we clean\n",
    "data1 = data.copy(deep=True)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2280b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "col_to_drop = ['NumberVmailMessages', 'TotalDayCharge', 'TotalEveCharge', 'TotalNightCharge', 'TotalIntlCharge']\n",
    "\n",
    "# Drop the columns from the DataFrame\n",
    "data1 = data1.drop(columns=col_to_drop)\n",
    "\n",
    "# Print the remaining columns in the DataFrame\n",
    "print(data1.columns)\n",
    "\n",
    "# Confirm multicollinearity has been eliminated\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix1 = data1.corr().round(2)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(corr_matrix1, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix After Dropping Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f6278",
   "metadata": {},
   "source": [
    "We no longer have features that are highly correlated and we can proceed to create the baseline logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31efeb68",
   "metadata": {},
   "source": [
    "### 4.2 Baseline Logistic Regression Model\n",
    "Train and evaluate a Baseline Model using Accuracy score (May be misleading for this model due to class imbalance), the AUC (Area Under the Curve) and ROC Curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f4b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libaries\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,roc_curve,auc,roc_auc_score\n",
    "\n",
    "# Split data1 into X an y\n",
    "y = data1['Churn']\n",
    "X = data1.drop('Churn',axis=1)\n",
    "\n",
    "# Split the data into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Instantiate LogisticRegression\n",
    "logreg = LogisticRegression(fit_intercept=False, solver='liblinear',C=1e12)\n",
    "\n",
    "# Fit to training data\n",
    "base_log_model = logreg.fit(X_train,y_train)\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "y_hat_test = logreg.predict (X_test)\n",
    "\n",
    "# Get Accuracy Score (This score may be misleading due to class imbalance)\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_hat_train))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "# Create the ROC Curve for both the train and test sets\n",
    "\n",
    "# Calculate the probability scores of each point for the train and test sets\n",
    "y_train_score = logreg.decision_function(X_train)\n",
    "y_test_score = logreg.decision_function(X_test)\n",
    "\n",
    "# Calculate the fpr(false positive rate),tpr(true positive rate) and thresholds for the train and test sets\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train,y_train_score)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test,y_test_score)\n",
    "\n",
    "# Print the AUC for the train and test sets\n",
    "print('Train AUC: {}'.format(auc(train_fpr, train_tpr)))\n",
    "print('Test AUC: {}'.format(auc(test_fpr, test_tpr)))\n",
    "\n",
    "# Plot the ROC curves for the train and test sets\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(train_fpr, train_tpr, color='blue',\n",
    "         lw=lw, label='Train ROC curve')\n",
    "plt.plot(test_fpr, test_tpr, color='darkorange',\n",
    "         lw=lw, label='Test ROC curve')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve (Baseline Model)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07621973",
   "metadata": {},
   "source": [
    "The model's performance metrics are quite promising. The accuracy and AUC scores for both the training and testing sets suggest that the model is performing well, with only a slight drop in performance on the test set. The Training Accuracy score shows that the model correctly predicts the class labels for about 90% and 88% of the training and test data respectively. The AUC score of 0.82 for the training set indicates good model performance, as it reflects a strong ability to distinguish between the classes.The AUC score of 0.79 for the test set, while slightly lower than the training AUC, is still quite good. This indicates that the model maintains a good level of performance on unseen data.  I will proceed with the SMOTE oversampling of the minority class to see if the model improves further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8258df",
   "metadata": {},
   "source": [
    "### 4.3 Handle Class Imbalance with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5941361",
   "metadata": {},
   "source": [
    "#### 4.3.1 Compare the Classes Before and After SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Compare the classes before and after SMOTE\n",
    "print('Original class distribution: \\n')\n",
    "print(y.value_counts())\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Preview synthetic sample class distribution\n",
    "print('-----------------------------------------')\n",
    "print('SMOTE sample class distribution: \\n')\n",
    "print(pd.Series(y_train_resampled).value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41560df",
   "metadata": {},
   "source": [
    "#### 4.3.2 Train and Evaluate Logistic Regression Model on Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model on oversampled data\n",
    "\n",
    "# Fit to training data\n",
    "base_log_model = logreg.fit(X_train_resampled,y_train_resampled)\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_hat_train = logreg.predict(X_train_resampled)\n",
    "y_hat_test = logreg.predict (X_test)\n",
    "\n",
    "# Get Accuracy Score \n",
    "print('Training Accuracy: ', accuracy_score(y_train_resampled, y_hat_train))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "# Create the ROC Curve for both the train and test sets\n",
    "\n",
    "# Calculate the probability scores of each point for the train and test sets\n",
    "y_train_score = logreg.decision_function(X_train_resampled)\n",
    "y_test_score = logreg.decision_function(X_test)\n",
    "\n",
    "# Calculate the fpr,tpr and thresholds for the train and test sets\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train_resampled,y_train_score)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test,y_test_score)\n",
    "\n",
    "# Print the AUC for the train and test sets\n",
    "print('Train Resampled AUC: {}'.format(auc(train_fpr, train_tpr)))\n",
    "print('Test AUC: {}'.format(auc(test_fpr, test_tpr)))\n",
    "\n",
    "# Plot the ROC curves for the train and test sets\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(train_fpr, train_tpr, color='blue',\n",
    "         lw=lw, label='Train ROC curve')\n",
    "plt.plot(test_fpr, test_tpr, color='darkorange',\n",
    "         lw=lw, label='Test ROC curve')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve (SMOTE)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1416b388",
   "metadata": {},
   "source": [
    "The model's training accuracy dropped to 78%, which is expected because SMOTE introduces synthetic examples to balance the classes, making the training data more challenging.The testing accuracy also decreased to 75%, indicating that the model's ability to generalize to unseen data has reduced. This drop is likely due to the more balanced yet synthetic nature of the training data.\n",
    "\n",
    "The AUC score of 0.86 for the resampled training set shows an improvement in the model's ability to distinguish between classes after SMOTE was applied.The AUC score of 0.75 for the test set indicates that, although the ability to distinguish between classes on the test data is slightly lower than before SMOTE, it is still relatively strong and reflects a more balanced performance.\n",
    "\n",
    "Applying SMOTE has addressed class imbalance, leading to a more balanced evaluation metric (AUC) for both training and test sets. While the accuracy scores decreased, the AUC scores, which are more informative for imbalanced datasets, show that the model's ability to discriminate between classes improved for the training set and remained relatively strong for the test set.\n",
    "\n",
    "Before SMOTE, the model might have been overfitting to the majority class, reflected in the high accuracy but lower AUC scores. After SMOTE, the model learns to better identify the minority class, which is crucial in imbalanced datasets.\n",
    "\n",
    "The decrease in accuracy suggests that the model trained on the resampled data is less biased towards the majority class but needs further fine-tuning (e.g., hyperparameter tuning, feature engineering) to improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b76a0c",
   "metadata": {},
   "source": [
    "### 4.4 Feature Selection with Random Forest\n",
    "\n",
    "In this section, I will try to further optimize the model through feature selection using Random Forest.\n",
    "\n",
    "+ Train Random Forest to determine feature importances\n",
    "+ Select Top Features based on importances\n",
    "+ Retrain Logistic Regression Model Using Selected Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48ddc7",
   "metadata": {},
   "source": [
    "#### 4.4.1 Train Random Forest to Determine Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Random Forest Clasifier \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# Train a Random Forest Model to calculate feature importances\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature':X_train.columns,'Importance':feature_importances})\n",
    "\n",
    "# Sort features by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False) \n",
    "importance_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52fd3a",
   "metadata": {},
   "source": [
    "#### 4.4.2 Select Top Features Based on Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features_list = [5, 7,10]\n",
    "\n",
    "# Define a function to evaluate models with different top features\n",
    "def evaluate_model_with_top_features(top_features_count):\n",
    "    top_features = importance_df['Feature'].head(top_features_count)\n",
    "    X_train_top = X_train_resampled[top_features]\n",
    "    X_test_top = X_test[top_features]\n",
    "    \n",
    "    # Train Logistic Regression model\n",
    "    logreg.fit(X_train_top, y_train_resampled)\n",
    "    \n",
    "   # Calculate the probability scores of each point for the train and test sets\n",
    "    y_train_score = logreg.decision_function(X_train_top)\n",
    "    y_test_pred_proba = logreg.decision_function(X_test_top)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    y_train_pred = logreg.predict(X_train_top)\n",
    "    y_test_pred = logreg.predict(X_test_top)\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Calculate ROC Curve\n",
    "    train_fpr, train_tpr, _ = roc_curve(y_train_resampled, y_train_score)\n",
    "    test_fpr, test_tpr, _ = roc_curve(y_test, y_test_score)\n",
    "    \n",
    "    # Calculate AUC\n",
    "    train_auc = auc(train_fpr, train_tpr)\n",
    "    test_auc = auc(test_fpr, test_tpr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'top_features': top_features_count,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'train_auc': train_auc,\n",
    "        'test_auc': test_auc,\n",
    "        'train_fpr': train_fpr,\n",
    "        'train_tpr': train_tpr,\n",
    "        'test_fpr': test_fpr,\n",
    "        'test_tpr': test_tpr\n",
    "    }\n",
    "\n",
    "# Evaluate models\n",
    "results = [evaluate_model_with_top_features(n) for n in top_features_list]\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(f\"Top {result['top_features']} Features\")\n",
    "    print(f\"Train Accuracy: {result['train_accuracy']}\")\n",
    "    print(f\"Test Accuracy: {result['test_accuracy']}\")\n",
    "    print(f\"Train AUC: {result['train_auc']}\")\n",
    "    print(f\"Test AUC: {result['test_auc']}\\n\")\n",
    "\n",
    "# Plot ROC Curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "for result in results:\n",
    "    plt.plot(result['train_fpr'], result['train_tpr'], lw=2, label=f\"Train ROC (Top {result['top_features']} Features, AUC = {result['train_auc']:.2f})\")\n",
    "    plt.plot(result['test_fpr'], result['test_tpr'], lw=2, linestyle='--', label=f\"Test ROC (Top {result['top_features']} Features, AUC = {result['test_auc']:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve with Different Top Features (SMOTE)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472006f4",
   "metadata": {},
   "source": [
    "With the top 5 features, the training accuracy is relatively low, indicating that the model might not be capturing sufficient information from the training set. The test accuracy is also low, suggesting limited generalization. However, the AUC scores are relatively close between training and testing, which indicates that the model can distinguish between classes to some extent.\n",
    "\n",
    "Adding two more features improves both the training and test accuracy. The AUC scores show a slight increase in training, but the test AUC remains stable. This suggests that additional features are providing more information and helping the model generalize better.\n",
    "\n",
    "With the top 10 features, there is a noticeable improvement in both training and test accuracy. The training AUC continues to improve, indicating better discrimination. However, the test AUC remains the same, suggesting that beyond a certain number of features, adding more does not significantly enhance the model's ability to distinguish between classes in the test set.\n",
    "\n",
    "Both train and test accuracy for the feature selection models are lower that that of the resampled SMOTE model. The train AUC IS lower too, but it remains stable. The test AUCs for the different feature sizes are the same with the SMOTE test AUC.\n",
    "\n",
    "Feature selection appears to have a negligible impact on the overall performance metrics of the model. I will proceed with cross- validation to ensure that model performance is consistent across different splits of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca5fa5c",
   "metadata": {},
   "source": [
    "### 4.5 Cross-Validation\n",
    "\n",
    "I will now perform cross-validation to assess how the model generalizes to an independent dataset. I will use the SMOTE resampled data and include all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17527829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Define the number of folds and scoring metric\n",
    "cv_folds = 5\n",
    "scoring_metrics = {'accuracy':'accuracy', 'auc':'roc_auc'}\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(logreg,X_train_resampled,y_train_resampled, cv=cv_folds, scoring=scoring_metrics, \n",
    "            return_train_score=True)\n",
    "\n",
    "# Evaluate cross-validation\n",
    "\n",
    "# Evaluate cross-validation results with rounding print(\"Cross-Validation Results:\") \n",
    "for metric in scoring_metrics: \n",
    "    train_scores = [round(score, 2) for score in cv_results['train_' + metric]] \n",
    "    test_scores = [round(score, 2) for score in cv_results['test_' + metric]] \n",
    "    mean_train_score = round(cv_results['train_' + metric].mean(), 2) \n",
    "    mean_test_score = round(cv_results['test_' + metric].mean(), 2) \n",
    "    std_train_score = round(cv_results['train_' + metric].std(), 2) \n",
    "    std_test_score = round(cv_results['test_' + metric].std(), 2) \n",
    "    \n",
    "    print(f\"{metric.capitalize()} - Train: {train_scores}\") \n",
    "    print(f\"{metric.capitalize()} - Test: {test_scores}\") \n",
    "    print(f\"Mean {metric.capitalize()} - Train: {mean_train_score}\") \n",
    "    print(f\"Mean {metric.capitalize()} - Test: {mean_test_score}\")\n",
    "    print(f\"Standard Deviation {metric.capitalize()} - Train: {std_train_score}\")\n",
    "    print(f\"Standard Deviation {metric.capitalize()} - Test: {std_test_score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4507d76",
   "metadata": {},
   "source": [
    "**Accuracy:** The training and testing accuracies are relatively close, indicating the model does not significantly overfit or underfit the data. However the testing accuracy variability indicates that the model's performance can vary based on the data split.\n",
    "\n",
    "**AUC:** Both training and test AUC values are high, showing the model's strong ability to distinguish between classes. The train results are quite consistent across folds while the variability in testing AUC suggests the need for careful interpretation.\n",
    "\n",
    "Overall the results show that the model performs well and generalizes effectively across different folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef683c",
   "metadata": {},
   "source": [
    "### 4.6 Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning will further optimize the model and potentially reduce variability in performance. I will use GridSearchCV for tuning the following hyperparameters:\n",
    "\n",
    "+ **max_iter:** This parameter specifies the maximum number of iterations taken for the solvers to converge. Our models so far have use 100, the default value.\n",
    "+ **C:** This is the inverse of the regularization strength; smaller values specify stronger regularization. Our models have used a very high value of C=1e12 (very small regularization). The default when not specified is 1.0.\n",
    "+ **solver:** This parameter determines the algorithm to use in the optimization problem. In our models, we are using 'liblinear'. The default value when not specified is 'lbfgs'.\n",
    "+ **penalty:** Ths parameter specifies the norm of the penalty. Our models so far, have used the deafaul L2 norm which is the Ridge Regularization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab135bc",
   "metadata": {},
   "source": [
    "#### 4.6.1 Tune the model to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data (solvers can be sensitive to the scale of features)\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = { \n",
    "    'C': [0.01, 0.1, 1, 10, 100], \n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n",
    "    'penalty': ['l2'], \n",
    "    'fit_intercept':[True, False],\n",
    "    'max_iter': [100,200,300,500,1000]}\n",
    "\n",
    "# Initialize GridSearchCV with multiple scoring metrics \n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid, \n",
    "              cv=5, scoring=['accuracy', 'roc_auc'], refit='roc_auc', return_train_score=True)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate the results\n",
    "best_params = grid_search.best_params_ \n",
    "best_score = grid_search.best_score_ \n",
    "print(\"Best Hyperparameters:\", best_params) \n",
    "print(\"Best AUC Score from Cross-Validation:\", best_score)\n",
    "\n",
    "# Get results for both metrics\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "accuracy_scores = results_df[results_df['mean_test_accuracy'].notnull()][['mean_test_accuracy','mean_test_roc_auc']]\n",
    "print(\"Grid Search Results for Accuracy and AUC:\") \n",
    "print(accuracy_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26daeb",
   "metadata": {},
   "source": [
    "#### 4.6.2 Retrain the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the best parameters\n",
    "\n",
    "best_model = LogisticRegression(random_state=42, **best_params)\n",
    "best_model.fit(X_train_resampled,y_train_resampled)\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_hat_train = best_model.predict(X_train_resampled)\n",
    "y_hat_test = best_model.predict (X_test)\n",
    "\n",
    "# Get Accuracy Score \n",
    "print('Training Accuracy: ', accuracy_score(y_train_resampled, y_hat_train))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "# Calculate the probability scores of each point for the train and test sets\n",
    "y_train_score = best_model.decision_function(X_train_resampled)\n",
    "y_test_score = best_model.decision_function(X_test)\n",
    "\n",
    "# Calculate the fpr,tpr and thresholds for the train and test sets\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train_resampled,y_train_score)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test,y_test_score)\n",
    "\n",
    "# Print the AUC for the train and test sets\n",
    "print('Train Resampled AUC: {}'.format(auc(train_fpr, train_tpr)))\n",
    "print('Test AUC: {}'.format(auc(test_fpr, test_tpr)))\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(train_fpr, train_tpr, color='blue',\n",
    "         lw=lw, label='Train ROC curve')\n",
    "plt.plot(test_fpr, test_tpr, color='darkorange',\n",
    "         lw=lw, label='Test ROC curve')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve (BEST MODEL)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64f4022",
   "metadata": {},
   "source": [
    "#### 4.6.3 Analyze the hyperparameter Tuning Results\n",
    "\n",
    "I will compare the tuned model with the SMOTE model using all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80094641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data Frame of bot sets of scores for better analysis\n",
    "\n",
    "data = { 'Metric': ['Training Accuracy', 'Testing Accuracy', 'Train Resampled AUC', 'Test AUC'],\n",
    "        'SMOTE Scores': [0.7796070100902814, 0.74, 0.8560079578327371, 0.7560655737704919], \n",
    "        'Tuned Scores': [0.80323951141795, 0.7685714285714286, 0.8783934518791693, 0.7796539162112932] }\n",
    "Analysis_df = pd.DataFrame(data)\n",
    "Analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596cc145",
   "metadata": {},
   "source": [
    "All metrics improved after hyperparameter tuning, which suggests that the runing process successfully enhanced the model's performance. Both the testing accuracy and test AUC improvements indicate better generalization to new data, reducing the risk of overfitting. The improvements are consistent accross both training and testing datasets, which is a positive sign that the model's enhancements are not just resticted to training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ad235",
   "metadata": {},
   "source": [
    "### 4.7 A Different Modeling Algorithm - Decision Trees\n",
    "\n",
    "I will tune the following parameters to get the best Decision Tree Model:\n",
    "+ **criterion:** This function measures the quality of a split. The default is 'gini' for the Gini impurity and 'entropy' for the information gain.\n",
    "+ **splitter:** This is the strategy used to chose the split at each node. I will assess 'best' that chooses the best split and 'random' that chooses the best random split. The default is 'best'\n",
    "+ **max_depth:** The maximum depth of a tree. If None, the nodes are expanded until all leaves are pure or until leaves contain less than min_samples_split samples\n",
    "+ **min_samples_split:** The minimum number of samples required to split an internal node. Default is 2.\n",
    "+ **min_samples_leaf:** The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. Default is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291781e",
   "metadata": {},
   "source": [
    "#### 4.7.1 Tune the Decision Tree model to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the hyperparameters for tuning the Decision Tree\n",
    "param_grid = {\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'splitter': ['best','random'],\n",
    "    'max_depth': [None,10,20,30,40,50],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf': [1,2,4]}\n",
    "\n",
    "# Use GridSerachCV to search over the defined parameter grid\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(tree_clf, param_grid, cv=5, scoring=['accuracy', 'roc_auc'], \n",
    "                refit='roc_auc', return_train_score=True)\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Extract the best parameters and evaluate the model's performance\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Hyperparameters for Decision Tree:\", best_params)\n",
    "print(\"Best AUC Score from Cross-Validation for Decision Tree:\", best_score)\n",
    "\n",
    "# Get results for both metrics\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "accuracy_scores = results_df[['mean_test_accuracy', 'mean_test_roc_auc']]\n",
    "print(\"Grid Search Results for Accuracy and AUC:\")\n",
    "print(accuracy_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b32ed",
   "metadata": {},
   "source": [
    "#### 4.7.2 Retrain the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the best parameters\n",
    "best_model_tree = DecisionTreeClassifier(random_state=42, **best_params)\n",
    "best_model_tree.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "\n",
    "# Calculate the probability scores of each point for the train and test sets\n",
    "y_train_score_tree = best_model_tree.predict_proba(X_train_resampled)[:,1]\n",
    "y_train_pred = best_model_tree.predict(X_train_resampled)\n",
    "y_test_score_tree = best_model_tree.predict_proba(X_test)[:,1]\n",
    "y_test_pred = best_model_tree.predict(X_test)\n",
    "\n",
    "# Calculate AUC and accuracy\n",
    "train_auc =roc_auc_score(y_train_resampled,y_train_score_tree)\n",
    "test_auc = roc_auc_score(y_test, y_test_score_tree) \n",
    "train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred) \n",
    "print(\"Train AUC:\", round(train_auc, 2))\n",
    "print(\"Test AUC:\", round(test_auc, 2)) \n",
    "print(\"Train Accuracy:\", round(train_accuracy, 2))\n",
    "print(\"Test Accuracy:\", round(test_accuracy, 2))\n",
    "\n",
    "# Calculate the fpr,tpr and thresholds for the train and test sets\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train_resampled,y_train_score_tree)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test,y_test_score_tree)\n",
    "\n",
    "# Print the AUC for the train and test sets\n",
    "print('Train Resampled AUC: {}'.format(auc(train_fpr, train_tpr)))\n",
    "print('Test AUC: {}'.format(auc(test_fpr, test_tpr)))\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(train_fpr, train_tpr, color='blue',\n",
    "         lw=lw, label='Train ROC curve')\n",
    "plt.plot(test_fpr, test_tpr, color='darkorange',\n",
    "         lw=lw, label='Test ROC curve')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve (BEST MODEL DECISION TREE)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604be87",
   "metadata": {},
   "source": [
    "#### 4.7.3 Analyze the Decsion Tree results\n",
    "\n",
    "I will compare the tuned Decision Tree Model results with the Best Logistic Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7699c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for the models\n",
    "data = {\n",
    "    'Metric': ['Training Accuracy', 'Testing Accuracy', 'Train Resampled AUC', 'Test AUC'],\n",
    "    'Decision Tree': [0.89, 0.88, 0.97319604172842, 0.8244444444444443],\n",
    "    'Logistic Regression Best Model': [0.8154540626659585, 0.7785714285714286, 0.8880714016373122, 0.785464480874317]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "final_model_analysis = pd.DataFrame(data)\n",
    "final_model_analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae731b38",
   "metadata": {},
   "source": [
    "+ **Decision Tree Model:** Higher training and testing accuracy, and higher AUC scores on both training and test sets.The very high training scores suggest the model might be overfitting. The big difference between the train and test AUC is indicative of a train model that is not generalizing as well to the unseen data.\n",
    "\n",
    "+ **Best Logistic Regression Model:** Shows more stable performance with less risk of overfitting, as indicated by the closer alignment between training and testing metrics. It has lower accuracy and AUC scores compared to the Decision Tree.\n",
    "\n",
    " **Conclusion**   \n",
    "The Decision Tree currently performs better in terms of accuracy and AUC on both the training and test sets. However, the risk of overfitting in the Decision Tree suggests that this model should be used with caution.  Logistic Regression, while showing lower metrics, provides a more balanced model with less overfitting risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d44a0",
   "metadata": {},
   "source": [
    "### 6.0 Summary and Recomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea0a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
